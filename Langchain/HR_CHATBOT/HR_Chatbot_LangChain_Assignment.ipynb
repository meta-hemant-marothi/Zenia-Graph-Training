{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27f2fc2",
   "metadata": {},
   "source": [
    "# ü§ñ HR Chatbot Assignment using LangChain and Organization Documents\n",
    "\n",
    "In this assignment, you'll build a simple HR chatbot using **LangChain**, powered by **Groq's LLaMA-3 API**, and answer employee queries based on your company documents.\n",
    "\n",
    "We'll guide you step-by-step, but you will complete the code blocks yourself using the hints provided.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Learning Objectives\n",
    "- Use LangChain to build a simple Retrieval-Augmented Generation (RAG) pipeline\n",
    "- Integrate Groq LLaMA-3 with LangChain\n",
    "- Load HR documents and retrieve relevant info\n",
    "- Answer employee queries using context-aware LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2a6fb",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Install Required Packages\n",
    "Install the required packages using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "935f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f18c4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Install the required packages\n",
    "# !pip install langchain faiss-cpu python-dotenv sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001e65f",
   "metadata": {},
   "source": [
    "## üîê Step 2: Load API Key from `.env`\n",
    "Make sure you have your Groq API key saved in `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fa20d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the API key using `load_dotenv()` and setup the LLM using LangChain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe70c9e",
   "metadata": {},
   "source": [
    "## üìÑ Step 3: Load Documents\n",
    "Use LangChain's `PyPDFLoader` or `TextLoader` to load files from `data/hr_docs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118accfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 7\n",
      "Employee Benefits - TechNova Solutions\n",
      "\n",
      "1. Health Insurance: Covered up to ‚Çπ5,00,000 annually for employee + dependents.\n",
      "2. Work From Home: Available up to 3 days per week with manager approval.\n",
      "3. Internet Reimbursement: ‚Çπ1,000 per month for remote workers.\n",
      "4. Learning & Development: Annual budget of ‚Çπ15,000 for courses, certifications.\n",
      "5. Wellness: Free access to yoga and meditation apps.\n",
      "6. Food Coupons: Monthly Sodexo coupons worth ‚Çπ2,000 for all full-time employees.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load documents from PDF or TXT\n",
    "from langchain.document_loaders import TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "txt_docs_path = Path(\"Data/hr_docs\")\n",
    "txt_files = list(txt_docs_path.glob(\"*.txt\"))\n",
    "\n",
    "txt_documents = []\n",
    "for file in txt_files:\n",
    "    loader = TextLoader(str(file), encoding=\"utf-8\")\n",
    "    txt_documents.extend(loader.load())\n",
    "\n",
    "print(f\"Total documents loaded: {len(txt_documents)}\")\n",
    "print(txt_documents[1].page_content[:500])  # Preview first document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee165b8",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Step 4: Chunk Documents\n",
    "Use `RecursiveCharacterTextSplitter` to split documents into manageable pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df5dd2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 18\n",
      "3. Use of Company Assets:\n",
      "   - Laptops and software licenses must be used only for work purposes.\n",
      "\n",
      "4. Social Media:\n",
      "   - Employees should avoid discussing confidential or controversial company topics online.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Split documents into smaller chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 50,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(txt_documents)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "print(chunks[1].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d615b32",
   "metadata": {},
   "source": [
    "## üß† Step 5: Embed and Store in FAISS\n",
    "Generate embeddings and store them in a FAISS vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2092764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate embeddings and store in FAISS\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the FAISS index\n",
    "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f25c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_index/hr_chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a241b8b",
   "metadata": {},
   "source": [
    "## üîç Step 6: Setup RetrievalQA Chain\n",
    "Create a chain that can retrieve chunks and answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "891c3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "    \"faiss_index/hr_chatbot\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64737d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create RetrievalQA chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae641e7e",
   "metadata": {},
   "source": [
    "## üí¨ Step 7: Ask Your Chatbot\n",
    "Now ask a question to your chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93788a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ HR Chatbot is ready! (type 'exit' to quit)\n",
      "\n",
      "Bot: The total number of leaves available for a woman is calculated by summing up all applicable leaves:\n",
      "\n",
      "- **Annual Leave**: 18 days\n",
      "- **Sick Leave**: 12 days\n",
      "- **Casual Leave**: 8 days\n",
      "- **Maternity Leave**: 182 days (26 weeks)\n",
      "\n",
      "Adding these together: 18 + 12 + 8 + 182 = 220 days.\n",
      "\n",
      "**Answer:** The total number of leaves available for a woman is 220 days. \n",
      "\n",
      "Bot: The total number of leaves available for a man is 48 days, comprising:\n",
      "\n",
      "- Annual Leave: 18 days\n",
      "- Sick Leave: 12 days\n",
      "- Casual Leave: 8 days\n",
      "- Paternity Leave: 10 days\n",
      "\n",
      "**Answer:** The total number of leaves for a man is 48 days. \n",
      "\n",
      "Bot: The total number of leaves available for men is calculated by summing up all applicable leaves:\n",
      "\n",
      "- **Annual Leave**: 18 days\n",
      "- **Sick Leave**: 12 days\n",
      "- **Casual Leave**: 8 days\n",
      "- **Paternity Leave**: 10 days\n",
      "- **Floating Holidays**: 2 days\n",
      "\n",
      "Adding these together: 18 + 12 + 8 + 10 + 2 = **50 days**.\n",
      "\n",
      "**Answer:** The total number of leaves for men is 50 days. \n",
      "\n",
      "Bot: The total number of leaves available for men is 50. This includes:\n",
      "\n",
      "- 18 Annual Leaves\n",
      "- 12 Sick Leaves\n",
      "- 8 Casual Leaves\n",
      "- 10 Paternity Leaves\n",
      "- 2 Floating Holidays\n",
      "\n",
      "Total: 18 + 12 + 8 + 10 + 2 = 50 leaves. \n",
      "\n",
      "üëã Goodbye! Stay compliant!\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ HR Chatbot is ready! (type 'exit' to quit)\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"üëã Goodbye! Stay compliant!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        response = qa_chain.invoke({\"question\": user_input})\n",
    "        print(\"Bot:\", response[\"answer\"].strip(), \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Oops! Something went wrong:\", str(e), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b247fa2",
   "metadata": {},
   "source": [
    "## ‚úÖ Done!\n",
    "Test different queries and documents to explore the chatbot's responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241343c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
