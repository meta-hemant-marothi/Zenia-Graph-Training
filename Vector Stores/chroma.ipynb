{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73a4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (4, 384)\n",
      "Example vector: [ 7.87396207e-02  1.93886999e-02  2.76507586e-02  8.64654109e-02\n",
      " -1.48537653e-02  1.60661265e-02 -1.60285213e-03 -3.76146659e-02\n",
      "  1.26939770e-02  6.24378286e-02 -1.05130471e-01 -1.56330224e-02\n",
      "  5.26266731e-02  5.99600859e-02 -1.59648228e-02  3.70125659e-02\n",
      " -4.81112301e-02  1.78382788e-02  1.17884483e-02  3.16210203e-02\n",
      " -7.95206148e-03  4.22672741e-02  1.44481838e-01  6.89757580e-04\n",
      "  5.40208910e-03  2.98592951e-02 -6.59526139e-03 -2.89774537e-02\n",
      " -2.43121497e-02  2.26081605e-03 -1.11427456e-01  4.93873581e-02\n",
      " -4.31133546e-02 -2.09824666e-02  3.36226784e-02 -1.79526005e-02\n",
      "  1.24976179e-02  1.35822315e-02  6.13042433e-03  6.93586171e-02\n",
      "  4.46974672e-02 -1.30910855e-02  2.06832960e-02 -3.53311598e-02\n",
      " -1.30466491e-01  1.02433870e-02  1.59708143e-03 -5.77524342e-02\n",
      "  5.72035611e-02  3.62285562e-02 -1.71939284e-03  3.27521153e-02\n",
      " -8.71543884e-02 -2.84104291e-02  1.83426198e-02  2.30656378e-02\n",
      "  5.38111664e-02 -1.74625050e-02  2.92159021e-02  1.16546489e-02\n",
      "  2.02571284e-02  1.43674716e-01  3.07236239e-02  3.40018384e-02\n",
      "  3.94728966e-02  3.18771750e-02 -3.33855785e-02  5.81679866e-02\n",
      " -2.42962921e-03 -1.81965102e-02 -3.65427211e-02  3.74042206e-02\n",
      " -4.13454399e-02 -3.34232971e-02 -3.81003618e-02  3.64427343e-02\n",
      "  1.11574300e-01 -2.64250934e-02  4.96019162e-02 -4.27178070e-02\n",
      " -1.99015765e-03 -3.89847755e-02  9.04130284e-04 -8.81775268e-05\n",
      "  1.24972183e-02  3.78741287e-02  5.42217232e-02 -6.32314710e-03\n",
      " -5.94860986e-02 -6.84625376e-03  6.53896406e-02 -3.86392325e-02\n",
      " -1.00422211e-01 -2.72845011e-02 -1.82053298e-02 -2.67762728e-02\n",
      "  2.25211307e-02  1.94139071e-02 -4.31892686e-02  3.87217216e-02\n",
      "  3.22376890e-03  2.02142056e-02  5.62220928e-04  7.09863007e-02\n",
      " -5.92786148e-02  3.78246047e-02 -2.37934734e-03  3.17062624e-02\n",
      "  1.21512413e-02  3.48977670e-02 -4.70964946e-02 -4.25405912e-02\n",
      "  2.69649252e-02  1.11762159e-01  5.62244244e-02  4.62114476e-02\n",
      "  2.98394654e-02  3.72509286e-02  9.75973010e-02  2.71830261e-02\n",
      "  5.81208691e-02 -2.16582022e-03 -4.71959589e-03 -7.06188083e-02\n",
      " -1.82639435e-02 -1.17632739e-01 -1.24368683e-01 -4.85457163e-33\n",
      "  2.62918213e-04 -7.96550736e-02 -4.84977812e-02  3.17050256e-02\n",
      "  6.60047829e-02 -5.09664752e-02 -5.13291210e-02  5.89148588e-02\n",
      " -7.77693093e-02  6.05827607e-02 -1.36353821e-01  3.45391035e-02\n",
      " -1.04473857e-03 -5.05771004e-02  2.29939464e-02 -8.25428665e-02\n",
      " -3.00541688e-02 -1.25744529e-02 -6.14836961e-02 -3.72193493e-02\n",
      "  7.59194652e-03  7.82955289e-02  1.51991695e-01  5.57036325e-02\n",
      " -7.96763971e-03 -1.36228487e-01 -3.08646280e-02 -6.78286254e-02\n",
      " -6.08553700e-02  3.59637756e-03  4.28044796e-03 -9.57909320e-03\n",
      "  4.87993751e-03  5.64683741e-03 -4.36596610e-02 -1.77522581e-02\n",
      " -1.66586693e-02  2.27760393e-02 -1.10180890e-02  3.45947780e-02\n",
      " -4.36769845e-03  1.97962746e-02 -9.26140416e-03  1.07205217e-03\n",
      "  5.41862845e-02  3.44557390e-02  1.84085499e-02  9.93004516e-02\n",
      "  2.47567729e-03 -1.21968752e-03  9.80397686e-02 -2.19653118e-02\n",
      " -4.72902060e-02 -2.45529488e-02  1.19032939e-05  2.64101475e-02\n",
      "  1.12612778e-02 -3.52684967e-02 -1.76735055e-02  6.58455268e-02\n",
      " -1.28995171e-02 -4.22351211e-02  4.92386557e-02 -1.01491064e-01\n",
      "  5.60958795e-02 -5.38695939e-02  7.08508492e-02 -4.71261516e-02\n",
      " -1.16979396e-02 -5.28687909e-02  3.65918986e-02  3.50524895e-02\n",
      " -1.28520494e-02 -5.69822639e-02 -4.07536477e-02 -6.53165057e-02\n",
      "  6.11125678e-02 -1.58793712e-03 -3.03177349e-02 -3.17725465e-02\n",
      "  1.13576412e-01 -4.07575257e-02  1.62497275e-02 -2.56228801e-02\n",
      "  1.86025293e-03  8.16167891e-03  7.52435531e-03 -2.60234158e-02\n",
      " -6.47152141e-02  7.69951716e-02 -5.30512594e-02 -2.32135486e-02\n",
      "  7.98730701e-02 -1.16758622e-01 -1.46509530e-02  4.49686723e-33\n",
      "  1.28156589e-02 -1.21055953e-01 -4.57910039e-02  7.46608479e-03\n",
      " -1.09703757e-01  5.28118685e-02 -6.48388267e-02 -7.77010471e-02\n",
      " -5.55136427e-02  1.33125082e-01  1.90786980e-02  2.82645766e-02\n",
      "  2.35175211e-02  3.56003754e-02  4.82527614e-02 -1.05538547e-01\n",
      "  4.90876362e-02 -9.56008490e-03  4.26980890e-02  8.25434923e-03\n",
      " -1.50133334e-02  6.26447648e-02 -1.24117576e-01  3.10522877e-02\n",
      "  7.26390928e-02  3.55816074e-02 -4.24791574e-02  9.09768566e-02\n",
      "  2.39419378e-02 -8.77135843e-02  6.18454516e-02 -5.14351130e-02\n",
      " -8.20386335e-02 -3.43988426e-02  3.31924744e-02  1.67415161e-02\n",
      " -7.69181699e-02 -2.81652715e-03  1.97760109e-02  1.06700771e-02\n",
      "  3.60608697e-02  4.92089167e-02  1.69309191e-02 -1.29867559e-02\n",
      "  2.86861956e-02 -1.90511644e-02 -1.91194955e-02 -1.58303007e-02\n",
      "  2.64675915e-02 -3.40646058e-02 -3.56608187e-03 -8.79157782e-02\n",
      " -4.56307754e-02 -1.91192925e-02 -4.20712233e-02  4.07934152e-02\n",
      "  2.68251393e-02  1.44505119e-02 -6.40043942e-03 -2.20729280e-02\n",
      "  1.06557943e-02  4.07622606e-02  4.21323627e-02 -1.08844396e-02\n",
      " -1.70004051e-02 -9.48500354e-03 -1.10486435e-04 -8.91512707e-02\n",
      "  2.22294126e-02 -3.69325951e-02  9.48743075e-02 -1.01082306e-02\n",
      " -8.35720599e-02  3.41671668e-02 -4.24198322e-02  2.13009845e-02\n",
      "  4.27902639e-02  2.70009600e-02  1.66507810e-02 -4.74478528e-02\n",
      "  2.34768186e-02 -1.47622908e-02  8.05960875e-03  4.98645715e-02\n",
      " -3.79076898e-02 -6.46026582e-02  7.93041140e-02  1.61724035e-02\n",
      " -5.22793643e-03  1.14976848e-02  3.86180021e-02 -4.67862189e-02\n",
      "  2.25913003e-02 -2.57341936e-02  5.53999618e-02 -1.33525564e-08\n",
      " -3.32998522e-02 -3.19119729e-02 -8.68151188e-02  5.92253730e-02\n",
      " -1.30530195e-02 -4.28098589e-02  6.82559907e-02 -1.38563111e-01\n",
      " -2.97776312e-02 -5.85747293e-05  7.57922903e-02 -5.26600145e-02\n",
      "  5.26038669e-02  3.89203094e-02  7.29228109e-02  6.04873225e-02\n",
      "  4.98925894e-02  3.03896870e-02  1.39919072e-02  1.44384289e-02\n",
      " -7.31424913e-02  4.09406684e-02 -6.02295138e-02 -3.20938267e-02\n",
      "  1.05193323e-02  2.25989008e-03 -3.90055254e-02 -1.31010525e-02\n",
      "  7.60472566e-02 -3.52573320e-02  1.10708755e-02 -4.68186289e-02\n",
      "  4.77113090e-02 -5.47886230e-02  2.55176425e-02 -6.89833164e-02\n",
      "  9.21792760e-02 -9.43992361e-02  5.84919639e-02 -4.71582897e-02\n",
      "  1.03000337e-02 -5.80156734e-03  3.66254300e-02 -9.86476690e-02\n",
      " -6.43881187e-02  1.31450994e-02  9.80447978e-02 -1.95480641e-02\n",
      " -2.18612961e-02  1.05353363e-01 -7.88937788e-03  7.39469528e-02\n",
      "  5.89220077e-02  1.13305356e-02 -3.26344259e-02 -3.88276614e-02\n",
      "  1.68380924e-02 -7.60360574e-03  4.59686145e-02  2.07159165e-02\n",
      "  4.11585160e-02  8.98555964e-02  6.34553358e-02  1.03838118e-02]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Some text to embed\n",
    "texts = [\n",
    "    \"Cats love sleeping.\",\n",
    "    \"Dogs are playful animals.\",\n",
    "    \"I enjoy programming in Python.\",\n",
    "    \"Redis can store vectors too!\"\n",
    "]\n",
    "\n",
    "# Get embeddings: a list of lists of numbers\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Example vector:\", embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4a232c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create Chroma client\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_db_impl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mduckdb+parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./chroma_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Create or get collection\u001b[39;00m\n\u001b[32m     11\u001b[39m collection = client.get_or_create_collection(\u001b[33m\"\u001b[39m\u001b[33mmy_collection\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\__init__.py:379\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(settings, tenant, database)\u001b[39m\n\u001b[32m    376\u001b[39m tenant = \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[32m    377\u001b[39m database = \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\api\\client.py:65\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     61\u001b[39m     tenant: \u001b[38;5;28mstr\u001b[39m = DEFAULT_TENANT,\n\u001b[32m     62\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m     63\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     64\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m.tenant = tenant\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m.database = database\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:19\u001b[39m, in \u001b[36mSharedSystemClient.__init__\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     16\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m._identifier = SharedSystemClient._get_identifier_from_settings(settings)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mSharedSystemClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_system_if_not_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:26\u001b[39m, in \u001b[36mSharedSystemClient._create_system_if_not_exists\u001b[39m\u001b[34m(cls, identifier, settings)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_system_if_not_exists\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mcls\u001b[39m, identifier: \u001b[38;5;28mstr\u001b[39m, settings: Settings\n\u001b[32m     24\u001b[39m ) -> System:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._identifier_to_system:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         new_system = \u001b[43mSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mcls\u001b[39m._identifier_to_system[identifier] = new_system\n\u001b[32m     29\u001b[39m         new_system.instance(ProductTelemetryClient)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\config.py:385\u001b[39m, in \u001b[36mSystem.__init__\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# Validate settings don't contain any legacy config values\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _legacy_config_keys:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    386\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    389\u001b[39m     settings[\u001b[33m\"\u001b[39m\u001b[33mchroma_segment_cache_policy\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m settings[\u001b[33m\"\u001b[39m\u001b[33mchroma_segment_cache_policy\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33mLRU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hemant\\Desktop\\Zenia Graph Training\\Vector Stores\\redis\\Lib\\site-packages\\chromadb\\config.py:319\u001b[39m, in \u001b[36mSettings.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# Error on legacy config values\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m _legacy_config_values:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[31mValueError\u001b[39m: \u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create Chroma client\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    "))\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\"my_collection\")\n",
    "\n",
    "# Add embeddings\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings.tolist(),  # Make sure it's a list of lists\n",
    "    ids=[f\"id_{i}\" for i in range(len(texts))]\n",
    ")\n",
    "\n",
    "# Search for similar text\n",
    "query = \"Which animal sleeps a lot?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935bc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abbaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a838397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e74b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a55530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a33fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63b698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cc797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e107ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf63b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f461d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "updated_document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "vector_store.update_document(document_id=uuids[0], document=updated_document_1)\n",
    "# You can also update multiple documents at once\n",
    "vector_store.update_documents(\n",
    "    ids=uuids[:2], documents=[updated_document_1, updated_document_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_by_vector(\n",
    "    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
